{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f9ba3c-8703-4b16-8af2-9d5d4d327b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PROJECT_ID=\"your-project-id\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../common/src\")\n",
    "sys.path.append(\"../src\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa76111-f1f8-4789-b202-4ca10a69abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [config/config.py:54 - <module>()] Namespace File not found, setting job namespace as default\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_GOOGLE_LLM = True\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_GOOGLE_MODEL_GARDEN = True\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_LLAMA2CPP_LLM = False\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_OPENAI_LLM = True\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_COHERE_LLM = True\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_TRUSS_LLAMA2 = True\n",
      "INFO: [config/config.py:248 - <module>()] Can't load llm_service_models.json: 404 Secret [projects/877759600672/secrets/llm_service_password_Llama2cpp] not found or has no versions.\n",
      "INFO: [config/config.py:260 - <module>()] LLM types loaded ['OpenAI-GPT3.5', 'OpenAI-GPT4', 'Cohere', 'VertexAI-Text', 'VertexAI-Chat-V1', 'VertexAI-Chat']\n",
      "INFO: [config/config.py:285 - <module>()] Embedding models loaded ['VertexAI-Embedding', 'OpenAI-Embeddings']\n",
      "INFO: [config/vector_store_config.py:38 - <module>()] Default vector store = [matching_engine]\n",
      "WARNING: [config/vector_store_config.py:53 - <module>()] Can't access postgres user password secret\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, BaseMultiActionAgent, AgentOutputParser\n",
    "from langchain.agents.chat.base import ChatAgent\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.llms import OpenAI, VertexAI\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.chains import LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "import re\n",
    "import config\n",
    "from config import (VERTEX_LLM_TYPE_BISON_CHAT,\n",
    "                    LLM_BACKEND_ROBOT_USERNAME,\n",
    "                    LLM_BACKEND_ROBOT_PASSWORD)\n",
    "from common.utils.token_handler import UserCredentials\n",
    "\n",
    "config.RULES_ENGINE_BASE_URL = f\"https://{PROJECT_ID}.cloudpssolutions.com/rules-engine/api/v1\"\n",
    "config.auth_client = UserCredentials(LLM_BACKEND_ROBOT_USERNAME,\n",
    "                              LLM_BACKEND_ROBOT_PASSWORD,\n",
    "                              f\"https://{PROJECT_ID}.cloudpssolutions.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa5f109-a246-4491-9c4e-dca297c748a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an AI Dispatch Assistant. An AI Planning Dispatch\n",
      "is an AI agent based on a large language model trained by Google.\n",
      "AI Dispatch Assistants are designed to be able to evaluate a question from a user\n",
      "and decide which routes to choose based on the context. The job of an AI Dispatch\n",
      "Assistant is to return the best matched agent_name in this format:\n",
      "'[agent_name] to [perform the action in this route]'.\n",
      "\n",
      "For example:\n",
      "- Use [query_engine] to run a query on a query engine with a specific domain knowledge.\n",
      "- Use [plan] to create and execute a plan.\n",
      "- Use [chat] to perform generic chat conversation.\n",
      "\n",
      "AI Dispatch Assistant will return only ONE route as the format below:\n",
      "- Use [query_engine] to run a query on a query engine with a specific domain knowledge.\n",
      "\n",
      "ROUTES:\n",
      "------\n",
      "\n",
      "    An AI Dispatch Assistant has access to the following routes:\n",
      "    - [plan] to create and execute a plan.\n",
      "    - [chat] to perform generic chat conversation.\n",
      "    - [query_engine_1] to run a query on a query engine for topics about driver license and state id.\n",
      "    - [query_engine_2] to run a query on a query engine for topics about the latest news in Jordan and the middle east.\n",
      "    \n",
      "    Choose one route based on the question below:\n",
      "    \n",
      "INFO: [agents/agents.py:107 - load_agent()] Successfully loaded DispatchAgent agent.\n"
     ]
    }
   ],
   "source": [
    "from services.agents.agents import DispatchAgent\n",
    "\n",
    "dispatch_agent = DispatchAgent(VERTEX_LLM_TYPE_BISON_CHAT)\n",
    "prefix = dispatch_agent.prefix + \"\"\"\n",
    "    An AI Dispatch Assistant has access to the following routes:\n",
    "    - [plan] to create and execute a plan.\n",
    "    - [chat] to perform generic chat conversation.\n",
    "    - [query_engine_1] to run a query on a query engine for topics about driver license and state id.\n",
    "    - [query_engine_2] to run a query on a query engine for topics about the latest news in Jordan and the middle east.\n",
    "    \n",
    "    Choose one route based on the question below:\n",
    "    \"\"\"\n",
    "dispatch_agent.set_prefix(prefix)\n",
    "# dispatch_agent.llm_type = \"VertexAI-Chat\"\n",
    "# dispatch_agent.agent_type = \"langchain_Conversational\"\n",
    "# dispatch_agent.agent_class = StructuredChatAgent\n",
    "\n",
    "print(dispatch_agent.prefix)\n",
    "\n",
    "tools = dispatch_agent.get_tools()\n",
    "agent = dispatch_agent.load_agent()\n",
    "\n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "      agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf9073c-d09c-4fec-895d-09f0a43b8285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "[ToolAgentOutputParser] text:  Task: How to apply for a state id\n",
      "Thought: The question is about applying for a state id, which is related to driver license and state id.\n",
      "Route:\n",
      "   1. Use [query_engine_1] to run a query on a query engine for topics about driver license and state id.\n",
      "\u001b[32;1m\u001b[1;3m Task: How to apply for a state id\n",
      "Thought: The question is about applying for a state id, which is related to driver license and state id.\n",
      "Route:\n",
      "   1. Use [query_engine_1] to run a query on a query engine for topics about driver license and state id.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "INFO: [agents/agent_service.py:259 - parse_output()] Parsing agent output: Route:, Task: How to apply for a state id\n",
      "Thought: The question is about applying for a state id, which is related to driver license and state id.\n",
      "Route:\n",
      "   1. Use [query_engine_1] to run a query on a query engine for topics about driver license and state id.\n",
      "['1. Use [query_engine_1] to run a query on a query engine for topics about driver license and state id.']\n"
     ]
    }
   ],
   "source": [
    "from services.agents.agent_service import parse_output\n",
    "\n",
    "prompt = \"How do I apply for a state id?\"\n",
    "agent_inputs = {\n",
    "    \"input\": prompt,\n",
    "    \"chat_history\": []\n",
    "  }\n",
    "output = agent_executor.run(agent_inputs)\n",
    "routes = parse_output(\"Route:\", output)\n",
    "print(routes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2072b76b-877c-43f0-8d52-50ad75c92622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'query_engine_1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_step(text:str) -> dict:\n",
    "  step_regex = re.compile(\n",
    "      r\"\\d+\\.\\s.*\\[(.*)\\]\\s?(.*)\", re.DOTALL)\n",
    "  matches = step_regex.findall(text)\n",
    "  return matches\n",
    "\n",
    "route, detail = parse_step(routes[0])[0]\n",
    "route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb59c5-dcc3-4636-bf2c-88534f5ba4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How do I apply for a driver's license?\"\n",
    "agent_inputs = {\n",
    "    \"input\": prompt,\n",
    "    \"chat_history\": []\n",
    "  }\n",
    "output = agent_executor.run(agent_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edfff6-d39c-4895-a0b3-e6c7d64464f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What's the latest news in Jordan?\"\n",
    "agent_inputs = {\n",
    "    \"input\": prompt,\n",
    "    \"chat_history\": []\n",
    "  }\n",
    "output = agent_executor.run(agent_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019d7db-e4a3-47c5-bbd1-9c86e587b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Compose and send an email to all the medicaid applicants that are missing income verification asking them to provide a pay stub from their employers\"\n",
    "agent_inputs = {\n",
    "    \"input\": prompt,\n",
    "    \"chat_history\": []\n",
    "  }\n",
    "output = agent_executor.run(agent_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2212e-d5d9-4350-924f-f871b3725cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
