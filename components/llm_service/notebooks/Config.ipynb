{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18679327-be5c-455c-95c5-bafaaf2bbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import inspect\n",
    "\n",
    "sys.path.append(\"../../common/src\")\n",
    "sys.path.append(\"../src\")\n",
    "os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee693e9-6bb0-405f-8bbf-716b2b2bb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PROJECT_ID=\"gcp-mira-develop\"\n",
    "project = \"gcp-mira-develop\"\n",
    "os.environ[\"PROJECT_ID\"] = project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2afc2b-23b0-4687-acaf-e23ee1204b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [utils/config.py:29 - get_environ_flag()] ENABLE_LLAMA2CPP_LLM = False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.utils.config import get_environ_flag\n",
    "ENABLE_LLAMA2CPP_LLM = get_environ_flag(\"ENABLE_LLAMA2CPP_LLM\", False)\n",
    "ENABLE_LLAMA2CPP_LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d91fd7d-6ab3-4355-90e7-bfa51be58d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [config/config.py:55 - <module>()] Namespace File not found, setting job namespace as default\n",
      "INFO: [utils/config.py:29 - get_environ_flag()] ENABLE_GOOGLE_LLM = True\n",
      "INFO: [utils/config.py:29 - get_environ_flag()] ENABLE_GOOGLE_MODEL_GARDEN = True\n",
      "INFO: [utils/config.py:29 - get_environ_flag()] ENABLE_LLAMA2CPP_LLM = False\n",
      "INFO: [utils/config.py:29 - get_environ_flag()] ENABLE_OPENAI_LLM = True\n",
      "INFO: [utils/config.py:29 - get_environ_flag()] ENABLE_COHERE_LLM = True\n",
      "INFO: [utils/config.py:29 - get_environ_flag()] ENABLE_TRUSS_LLAMA2 = True\n",
      "INFO: [config/config.py:241 - <module>()] Can't load llm_service_models.json: [Errno 2] No such file or directory: '/Users/lramsey/work/ailp/lukmanr-gps-core-solution-services/components/llm_service/src/config/llm_service_models.json'\n",
      "INFO: [config/config.py:251 - <module>()] LLM types loaded ['OpenAI-GPT3.5', 'OpenAI-GPT4', 'Cohere', 'VertexAI-Text', 'VertexAI-Chat-V1', 'VertexAI-Chat', 'Truss-Llama2-Chat']\n",
      "INFO: [config/config.py:276 - <module>()] Embedding models loaded ['VertexAI-Embedding', 'OpenAI-Embeddings']\n",
      "INFO: [config/vector_store_config.py:38 - <module>()] Default vector store = [matching_engine]\n"
     ]
    }
   ],
   "source": [
    "from config.model_config import ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d72a529-2a4e-44e7-8450-c44f45eaf4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path = os.path.join(\"config\", \"models.json\")\n",
    "model_config = ModelConfig(model_config_path)\n",
    "model_config.read_model_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a987f5-b796-492a-9b41-f37c117d3e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VertexAI-Text': {'is_chat': False, 'provider': 'Vertex'},\n",
       " 'VertexAI-Chat-Palm2V2': {'is_chat': True,\n",
       "  'provider': 'Vertex',\n",
       "  'model_name': 'chat-bison@002'},\n",
       " 'VertexAI-Chat-Palm2-32k': {'is_chat': True,\n",
       "  'provider': 'Vertex',\n",
       "  'model_name': 'chat-bison-32k'},\n",
       " 'Truss-Llama2-Chat': {'api_base_url': '34.171.143.157:8080',\n",
       "  'is_chat': True,\n",
       "  'provider': 'Truss',\n",
       "  'enabled': False},\n",
       " 'VertexAI-ModelGarden-LLAMA2-Chat': {'is_chat': True,\n",
       "  'provider': 'ModelGarden',\n",
       "  'enabled': False},\n",
       " 'OpenAI-GPT4': {'is_chat': True,\n",
       "  'provider': 'Langchain',\n",
       "  'enabled': True,\n",
       "  'api_key': 'openai-api-key',\n",
       "  'model_name': 'gpt-4'},\n",
       " 'OpenAI-GPT3.5': {'is_chat': True,\n",
       "  'provider': 'Langchain',\n",
       "  'enabled': True,\n",
       "  'api_key': 'openai-api-key',\n",
       "  'model_name': 'gpt-3.5-turbo'},\n",
       " 'Cohere': {'is_chat': True,\n",
       "  'provider': 'Langchain',\n",
       "  'enabled': True,\n",
       "  'api_key': 'cohere-api-key'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.llm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d59ce3b-e8de-46d2-8af1-3e64b3345fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vertex': {'enabled': True, 'env_flag': 'ENABLE_GOOGLE_LLM'},\n",
       " 'ModelGarden': {'enabled': True, 'env_flag': 'ENABLE_GOOGLE_MODEL_GARDEN'},\n",
       " 'Langchain': {'enabled': True, 'env_flag': 'ENABLE_LANGCHAIN_LLM'},\n",
       " 'LLMService': {'enabled': True, 'env_flag': 'ENABLE_LLM_SERVICE_LLM'},\n",
       " 'Truss': {'enabled': True, 'env_flag': 'ENABLE_TRUSS_LLAMA2'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.llm_model_providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bd20ac-93bd-476d-a336-9eccd2ad4f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Llama2cpp': {'user': 'lramsey@google.com',\n",
       "  'api_base_url': 'http://model-service/api/v1',\n",
       "  'provider': 'LLMService'},\n",
       " 'VertexAI-Embedding': {'provider': 'Vertex'},\n",
       " 'OpenAI-Embedding': {'provider': 'Langchain'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.llm_embedding_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c188ada5-a690-4557-b457-053d05419c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for VertexAI-Text to True\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for VertexAI-Chat-Palm2V2 to True\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for VertexAI-Chat-Palm2-32k to True\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for Truss-Llama2-Chat to False\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for VertexAI-ModelGarden-LLAMA2-Chat to False\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for OpenAI-GPT4 to True\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for OpenAI-GPT3.5 to True\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for Cohere to True\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for Llama2cpp to True\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for VertexAI-Embedding to True\n",
      "INFO: [config/model_config.py:186 - set_model_config()] Setting model enabled flag for OpenAI-Embedding to True\n"
     ]
    }
   ],
   "source": [
    "model_config.set_model_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3c66991-256d-411f-a197-1d12f3a1ed58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OpenAI-GPT3.5',\n",
       " 'OpenAI-GPT4',\n",
       " 'Cohere',\n",
       " 'VertexAI-Text',\n",
       " 'VertexAI-Chat-V1',\n",
       " 'VertexAI-Chat',\n",
       " 'Truss-Llama2-Chat']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import LLM_TYPES\n",
    "LLM_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7093626-e520-49ec-a170-0a30a4aa235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VertexAI-Text',\n",
       " 'VertexAI-Chat-Palm2V2',\n",
       " 'VertexAI-Chat-Palm2-32k',\n",
       " 'OpenAI-GPT4',\n",
       " 'OpenAI-GPT3.5',\n",
       " 'Cohere']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_config.get_llm_types())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a37d28-3823-4595-9221-570fed018e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.is_model_enabled(\"VertexAI-ModelGarden-LLAMA2-Chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c84257-d0e6-4b63-936a-0fa7b4907e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
