{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f9ba3c-8703-4b16-8af2-9d5d4d327b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../common/src\")\n",
    "sys.path.append(\"../src\")\n",
    "os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c6b8e1-4ecd-40d3-bede-e906d1686155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, BaseMultiActionAgent, AgentOutputParser\n",
    "from langchain.agents.chat.base import ChatAgent\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.llms import OpenAI, VertexAI\n",
    "from langchain.chat_models import ChatVertexAI, ChatOpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.chains import LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c68b1d-aea4-456c-ac69-2c7854f67bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PROJECT_ID=\"gcp-mira-demo\"\n",
    "project = \"gcp-mira-demo\"\n",
    "os.environ[\"PROJECT_ID\"] = project\n",
    "PROJECT_ID = project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa76111-f1f8-4789-b202-4ca10a69abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [config/config.py:54 - <module>()] Namespace File not found, setting job namespace as default\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_GOOGLE_LLM = True\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_GOOGLE_MODEL_GARDEN = True\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_LLAMA2CPP_LLM = False\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_OPENAI_LLM = True\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_COHERE_LLM = True\n",
      "INFO: [config/config.py:87 - get_environ_flag()] ENABLE_TRUSS_LLAMA2 = True\n",
      "INFO: [config/config.py:246 - <module>()] Can't load llm_service_models.json: 404 Secret [projects/63101149566/secrets/llm_service_password_Llama2cpp] not found or has no versions. [detail: \"[ORIGINAL ERROR] generic::not_found: Secret [projects/63101149566/secrets/llm_service_password_Llama2cpp] not found or has no versions. [google.rpc.error_details_ext] { message: \\\"Secret [projects/63101149566/secrets/llm_service_password_Llama2cpp] not found or has no versions.\\\" }\"\n",
      "]\n",
      "INFO: [config/config.py:258 - <module>()] LLM types loaded ['OpenAI-GPT3.5', 'OpenAI-GPT4', 'Cohere', 'VertexAI-Text', 'VertexAI-Chat-V1', 'VertexAI-Chat']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LLM_SERVICE_EMBEDDING_MODELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (VERTEX_LLM_TYPE_BISON_CHAT,\n\u001b[1;32m      3\u001b[0m                     VERTEX_LLM_TYPE_BISON_TEXT,\n\u001b[1;32m      4\u001b[0m                     OPENAI_LLM_TYPE_GPT3_5,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m                     LLM_BACKEND_ROBOT_USERNAME,\n\u001b[1;32m      8\u001b[0m                     LLM_BACKEND_ROBOT_PASSWORD)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoken_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UserCredentials\n",
      "File \u001b[0;32m~/development/mira_v1/core-solution-services/components/llm_service/src/config/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2023 Google LLC\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03mConfig for LLM service\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# platform config\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     PROJECT_ID,\n\u001b[1;32m     20\u001b[0m     GCP_PROJECT,\n\u001b[1;32m     21\u001b[0m     REGION,\n\u001b[1;32m     22\u001b[0m     SKAFFOLD_NAMESPACE,\n\u001b[1;32m     23\u001b[0m     GKE_CLUSTER,\n\u001b[1;32m     24\u001b[0m     GCP_ZONE,\n\u001b[1;32m     25\u001b[0m     DATABASE_PREFIX,\n\u001b[1;32m     26\u001b[0m     USER_MANAGEMENT_BASE_URL,\n\u001b[1;32m     27\u001b[0m     RULES_ENGINE_BASE_URL,\n\u001b[1;32m     28\u001b[0m     SERVICES,\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# service config\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     LLM_SERVICE_PATH,\n\u001b[1;32m     32\u001b[0m     PORT,\n\u001b[1;32m     33\u001b[0m     API_BASE_URL,\n\u001b[1;32m     34\u001b[0m     CONTAINER_NAME,\n\u001b[1;32m     35\u001b[0m     DEPLOYMENT_NAME,\n\u001b[1;32m     36\u001b[0m     SERVICE_NAME,\n\u001b[1;32m     37\u001b[0m     PAYLOAD_FILE_SIZE,\n\u001b[1;32m     38\u001b[0m     ERROR_RESPONSES,\n\u001b[1;32m     39\u001b[0m     JOB_NAMESPACE,\n\u001b[1;32m     40\u001b[0m     auth_client,\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# secrets\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     LLM_BACKEND_ROBOT_USERNAME,\n\u001b[1;32m     44\u001b[0m     LLM_BACKEND_ROBOT_PASSWORD,\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# LLM types\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     LLM_TYPES,\n\u001b[1;32m     48\u001b[0m     CHAT_LLM_TYPES,\n\u001b[1;32m     49\u001b[0m     OPENAI_LLM_TYPE_GPT3_5,\n\u001b[1;32m     50\u001b[0m     OPENAI_LLM_TYPE_GPT4,\n\u001b[1;32m     51\u001b[0m     COHERE_LLM_TYPE,\n\u001b[1;32m     52\u001b[0m     VERTEX_LLM_TYPE_BISON_TEXT,\n\u001b[1;32m     53\u001b[0m     VERTEX_LLM_TYPE_BISON_CHAT,\n\u001b[1;32m     54\u001b[0m     VERTEX_AI_MODEL_GARDEN_LLAMA2_CHAT,\n\u001b[1;32m     55\u001b[0m     TRUSS_LLM_LLAMA2_CHAT,\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# LLM config\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     ENABLE_OPENAI_LLM,\n\u001b[1;32m     59\u001b[0m     ENABLE_COHERE_LLM,\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# LLM models and collections of models\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     DEFAULT_QUERY_CHAT_MODEL,\n\u001b[1;32m     63\u001b[0m     DEFAULT_QUERY_EMBEDDING_MODEL,\n\u001b[1;32m     64\u001b[0m     GOOGLE_LLM,\n\u001b[1;32m     65\u001b[0m     LANGCHAIN_LLM,\n\u001b[1;32m     66\u001b[0m     EMBEDDING_MODELS,\n\u001b[1;32m     67\u001b[0m     LANGCHAIN_EMBEDDING_MODELS,\n\u001b[1;32m     68\u001b[0m     VERTEX_EMBEDDING_MODELS,\n\u001b[1;32m     69\u001b[0m     LLM_SERVICE_EMBEDDING_MODELS,\n\u001b[1;32m     70\u001b[0m     GOOGLE_MODEL_GARDEN,\n\u001b[1;32m     71\u001b[0m     LLM_SERVICE_MODELS,\n\u001b[1;32m     72\u001b[0m     LLM_TRUSS_MODELS,\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# agent config\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     AGENT_CONFIG_PATH,\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_store_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     79\u001b[0m   DEFAULT_VECTOR_STORE,\n\u001b[1;32m     80\u001b[0m   VECTOR_STORES\n\u001b[1;32m     81\u001b[0m   )\n",
      "File \u001b[0;32m~/development/mira_v1/core-solution-services/components/llm_service/src/config/config.py:280\u001b[0m\n\u001b[1;32m    272\u001b[0m   LANGCHAIN_EMBEDDING_MODELS\u001b[38;5;241m.\u001b[39mappend(LLAMA2CPP_LLM_TYPE_EMBEDDING)\n\u001b[1;32m    273\u001b[0m   LANGCHAIN_LLM\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    274\u001b[0m     LLAMA2CPP_LLM_TYPE_EMBEDDING: LlamaCppEmbeddings(model_path\u001b[38;5;241m=\u001b[39mLLAMA2CPP_MODEL_PATH)\n\u001b[1;32m    275\u001b[0m   })\n\u001b[1;32m    278\u001b[0m EMBEDDING_MODELS \u001b[38;5;241m=\u001b[39m VERTEX_EMBEDDING_MODELS \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    279\u001b[0m                    LANGCHAIN_EMBEDDING_MODELS \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m--> 280\u001b[0m                    \u001b[43mLLM_SERVICE_EMBEDDING_MODELS\u001b[49m\n\u001b[1;32m    282\u001b[0m DEFAULT_QUERY_EMBEDDING_MODEL \u001b[38;5;241m=\u001b[39m VERTEX_LLM_TYPE_GECKO_EMBEDDING\n\u001b[1;32m    283\u001b[0m Logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding models loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEMBEDDING_MODELS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LLM_SERVICE_EMBEDDING_MODELS' is not defined"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from config import (VERTEX_LLM_TYPE_BISON_CHAT,\n",
    "                    VERTEX_LLM_TYPE_BISON_TEXT,\n",
    "                    OPENAI_LLM_TYPE_GPT3_5,\n",
    "                    OPENAI_LLM_TYPE_GPT4,\n",
    "                    COHERE_LLM_TYPE,\n",
    "                    LLM_BACKEND_ROBOT_USERNAME,\n",
    "                    LLM_BACKEND_ROBOT_PASSWORD)\n",
    "from common.utils.token_handler import UserCredentials\n",
    "config.TOOLS_SERVICE_BASE_URL = \"https://gcp-mira-demo.cloudpssolutions.com/tools-service/api/v1\"\n",
    "config.auth_client = UserCredentials(LLM_BACKEND_ROBOT_USERNAME,\n",
    "                              LLM_BACKEND_ROBOT_PASSWORD,\n",
    "                              \"https://gcp-mira-demo.cloudpssolutions.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ce13c-baf4-44e2-b48e-6ffd283ee08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.SERVICES['tools-service']['host']='https://gcp-mira-demo.cloudpssolutions.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92a118-985d-4815-8dda-b19d73599b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.SERVICES['tools-service']['api_url_prefix']='https://gcp-mira-demo.cloudpssolutions.com/tools-service/api/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36729e2c-cf64-4862-81c0-dfca35191c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.SERVICES['tools-service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67079e21-816e-418f-9152-f0f056c44f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.models import Agent\n",
    "from common.models.agent import AgentType, UserPlan, PlanStep\n",
    "from services.agents.agent_service import get_agent_config, get_plan_agent_config,agent_execute_plan, run_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb952721-b985-481b-9e7e-c50124e9ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.agents.agents import TaskAgent, PlanAgent\n",
    "#casey_plan_agent = TaskAgent(VERTEX_LLM_TYPE_BISON_TEXT)\n",
    "#casey_plan_agent = TaskAgent(VERTEX_LLM_TYPE_BISON_CHAT)\n",
    "#casey_plan_agent = TaskPlanAgent(OPENAI_LLM_TYPE_GPT3_5)\n",
    "#casey_plan_agent = TaskAgent(OPENAI_LLM_TYPE_GPT4)\n",
    "casey_plan_agent = TaskAgent(OPENAI_LLM_TYPE_GPT4)\n",
    "#casey_plan_agent = TaskPlanAgent(COHERE_LLM_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1925b32-48f0-4d92-a8f6-c2a501ce1c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Compose and send an email to all the medicaid applicants that are missing income verification asking them to provide a pay stub from their employers\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5f109-a246-4491-9c4e-dca297c748a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"5nJrkPWa3D0yCKA853mD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b3a5a1-ad41-42c6-8f74-b23bedfc836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent_executor.run(agent_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a4d14-dba7-4e83-92b0-f38c3c767eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.agents.agent_service import agent_plan, parse_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e38ee6-46e7-421a-a441-d60bee40e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = agent_plan(\"Plan\", prompt, user_id)\n",
    "\n",
    "user_plan = plan[1]\n",
    "plan_steps=user_plan.plan_steps\n",
    "chat_history = []\n",
    "\n",
    "for step in plan_steps:\n",
    "    description = PlanStep.find_by_id(step).description\n",
    "    chat_history.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed7efe-b7f4-45a0-9974-f1476a42b864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tools = casey_plan_agent.get_tools()\n",
    "print(tools)\n",
    "\n",
    "agent = casey_plan_agent.load_agent()\n",
    "\n",
    "prompt = \"\"\"You are an AI assistant that can execute steps by calling upon the right tools. You have access to all the information required to execute the plan by from the values returned by the tools . Execute the steps as outlined in the following numbered list \"\"\"\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "  agent=agent, \n",
    "    tools=tools,\n",
    "    verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28d4bb-e125-4b54-af09-d4ffcc88dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat_history[0]= '1. Use [query_tool] to [ find Medicaid applicants missing a pay stub ]'\n",
    "#chat_history[2] = '3. Use [gmail_tool] to [send the composed email to the identified applicants]' \n",
    "#chat_history.insert(1,'Use [docs_tool] to [compose an email asking for a pay stub from their employers]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ddf3c-4b3e-4c18-9c37-b3e52bf2e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history_string = ''.join(chat_history)\n",
    "agent_inputs = {\n",
    "    \"input\": prompt + chat_history_string\n",
    "}\n",
    "#agent_inputs = {\n",
    "#    \"input\": prompt, \n",
    "#    'chat_history':chat_history\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f917e8-1ac6-4100-861a-307082773039",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_inputs['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73f802-8fb6-49d7-a833-165c2d9ffe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.run(agent_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f8a31-4ed1-4c6d-9347-ccc30c9b2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call agent_service that looks up the plan steps for a given User Plan\n",
    "agent_execute_plan(agent_name='Task', prompt=,user_plan=user_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581158f4-2e2b-4dfb-b0be-311f9f45a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_agent(agent_name='Task', prompt=agent_inputs['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1141436c-e0fa-43f3-bdca-a187590c702e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
